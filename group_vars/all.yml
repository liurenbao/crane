---
## Kubernetes
## ********************************************************************************************************************************
# 部署 Kubernetes 对应版本, 不建议修改, 如需修改请修改小版本进行部署测试, 大版本会引发部署参数不支持等问题.
# 如使用镜像方式部署, 不能修改
# https://github.com/kubernetes/kubernetes/releases
k8s_version: 'v1.16.2'

# 避免大版本中组件的版本差异, 使用 build 版本作为差异配置项, 在项目中可以看做如下使用 '{{ k8s_version }}.{{ build_k8s_version }}'
build_k8s_version: '7'

# 部署 CNI 对应版本, 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
# https://github.com/containernetworking/plugins/releases/
cni_version: 'v0.8.2'

# CNI OS Type
cni_os_drive: 'linux-amd64'

# 获取当前需要部署的 Kubernetes Master 总数量, 配置数量在 nodes 文件中获取
k8s_master_counts: "{{ groups['kube-master'] | length }}"

# 获取当前需要部署的 Kubernetes Node 总数量, 配置数量在 nodes 文件中获取
all_nodes_counts: "{{ groups['all'] | length }}"

# Kubernetes ApiServer 监听的端口号
k8s_master_apiservice_bind_port: 5443

# Kubernetes HaProxy 监听的端口号
# 在部署的 Kubernetes 集群架构中, 使用 HaProxy 作为 apiServer 负载均衡设备, 集群架构应为 SLB > HaProxy > apiServer
# 请自行设置端口号, 最好保持默认值
k8s_master_haproxy_bind_port: 6443

# Kubernetes 在集群中使用的 ClusterIP, 此地址依赖 k8s_cluster_ip_range 的网段
k8s_cluster_ip: '10.96.0.1'

# Kubernetes 集群使用的 ClusterIP 网段
k8s_cluster_ip_range: '10.96.0.0/12'

# Kubernetes ApiServer 的总入口地址, 可配置 SLB 等云服务商提供的地址, 但需要接入后端服务器的 80, 443 端口, 此地址可以写某个单实例的 IP 地址
k8s_load_balance_ip: 172.17.48.104

# Kubernetes HaProxy 监听的 apiServer 完整的 URL
k8s_apiserver_https_bind: 'https://{{ k8s_load_balance_ip }}:{{ k8s_master_haproxy_bind_port }}'

# Kubernetes 可暴露的 NodePort 端口号
k8s_apiserver_node_port_range: '10-38878'

# 判定值, 勿动
is_kube_master: "{{ inventory_hostname in groups['kube-master'] }}"
is_kube_node: "{{ inventory_hostname in groups['kube-node'] }}"

# 是否使用本地文件, 例如 kubectl, image 方式部署, 此项只能适用于容器方式部署, 但与 is_using_image_deploy 参数有冲突关系, 此值为本地镜像打包方式部署, is_using_image_deploy 为远程镜像方式部署。
is_using_local_files_deploy: false

# 是否使用远程镜像部署, 例如 kubectl, image 默认为 true
# 如果使用镜像部署需要保证 Ansible 中 *_version 未被修改的情况下才可使用, 否则版本不一致造成的问题自行解决.
# 如果服务器是在国内, 强烈推荐使用此值设为 true, 并保证可以获取 docker hub 镜像资源.
is_using_image_deploy: true

# 此值为镜像仓库部署时, 使用的镜像仓库地址, 如果需要自定义, 请把指定镜像放置在自定义仓库内, 并指定相同的 tag
k8s_image_deploy_repo: 'slzcc/kubernetes'

# 是否开启 Master 节点调度, 默认为 true. 
is_kube_master_schedule: true

# Pause Version
# 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
pause_version: '3.1'

# infra image, 依赖下方镜像仓库地址
k8s_pod_infra_container_image: "{{ k8s_cluster_component_registry }}/pause:{{ pause_version }}"

# Kubernetes Cluster Registry Addr, 默认值为: k8s.gcr.io
# 此地址可以修改为自定义镜像地址, 但需要确保已经执行 script/PublishK8sRegistryImages.sh 脚本, 所以参数可改为 slzcc, 如果在国内可使用 docker.io/slzcc 获取镜像。
# 受影响的镜像为: etcd、kube-apiserver-amd64、kube-controller-manager、kube-scheduler、kube-proxy、pause。
# 此值依赖于 is_kube_master_schedule, 如果使用镜像方式部署时, 此值不能变动
k8s_cluster_component_registry: 'k8s.gcr.io'

# 是否使用 RBAC, 集群默认是 RBAC 认证, 但可以在部署完集群之后创建超级用户取消所有限制
is_rbac: false

## Kuber Network
## ********************************************************************************************************************************

# 第三方网络设备绑定的网络设备配置，需要集群内绑定的网卡名称统一，也就是说所有的内部外部通信走一块网卡
# Etcd 绑定的宿主机网卡, 此配置需要在启动 Etcd 的节点上强制网卡名称一致
# 如果配置了 Keepalived 则 Keepalived 也会绑定到这块网卡上，暂不支持多网卡
os_network_device_name: 'eth0'

## Keepalived
## ********************************************************************************************************************************

# 是否使用 Keepalived, 在非公有云/私有云环境中, 需要借助 keepalived 进行服务集群的高可用, 它的位置在类 SLB 层
is_keepalived: false

# Keepalived 绑定的 IP 地址, 它在 HaProxy 的上一层
keepalived_ip: "{{ k8s_load_balance_ip }}"

# Keepalived 绑定的物理网卡名称
vip_bind_net_device: "{{ os_network_device_name }}"

## Kube Proxy
## ********************************************************************************************************************************

# Kube Proxy 模式, 默认 ipvs, 如果设置为空则默认使用 iptable
kube_proxy_mode: "ipvs"

# 是否安装 ipvsadm
is_install_ipvsadm: true

# 如果配置了 Keepalived 就需要配置绑定的 nodePort 的物理网段，否则 Keepalived 的流量无法到达 nodePort, 因为 Keepalived 会发送 ARP 请求到此网段内，如果不设置这个网段则会流量不可达. v1.15.3.5 中修复。
# 如果物理网段为 10.100.21.0/24, 请把值写入下方配置即可.
kube_proxy_node_port_addresses: "172.17.48.0/24"

# ipvs 调度策略.
kube_proxy_ipvs_scheduler: "rr"

## Kubelet Config
## ********************************************************************************************************************************
# Kubelet Options
## 不区分 Master/Nodes
kubelet_options: "--cgroup-driver={{ kubelet_cgroup_drive }} --network-plugin=cni --cni-conf-dir={{ cni_config_dir }} --cni-bin-dir={{ kubernetes_cni_dirs }} --pod-infra-container-image={{ k8s_pod_infra_container_image }} --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"

## GC Config, (没有应用, 如需要请加入 kubelet_options 配置内, 请熟悉文档中的每一项参数功能再进行配置)
## GC DOCS https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/
kubectl_gc_options: "--eviction-hard=memory.available<500Mi,nodefs.available<1Gi,imagefs.available<50Gi --eviction-minimum-reclaim='memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi' --system-reserved=memory=1.5Gi"

## External Proxy
## ********************************************************************************************************************************
# 执行过程中使用 Wget or Curl 时可以借助代理执行. (下载包文件与镜像部署方式没有交集，镜像部署已经包含这一步骤)

# HTTP Proxy
http_proxy: ""

# HTTPS Proxy
https_proxy: ""

## System Config
## ********************************************************************************************************************************

# 部署的 Cluster 中 Containers 的时区, 由于是挂载宿主机 /usr/share/zoneinfo 目录解决, 所以要保证此目录的存在。
# 如果需要设置 UTC 时区, 请设置值为: Europe/Moscow
time_location: "Asia/Shanghai"

## Kube TLS
## ********************************************************************************************************************************

# CFSSL 生成证书的加密方式
tls_k8s_encryption_algorithm: 'rsa'

# CFSSL 生成证书的通过加密算法生成的长度
tls_k8s_encryption_algorithm_size: 2048

# 证书有效期, 默认为 5 年, 因 CA 根证书默认为 5 年, 此值改大没意义
tls_k8s_validity_period: 5

# 证书信息头, 国家信息 
# Country Name
tls_k8s_head_info_C: 'CN'

# 证书信息头, 地区或城市 
# Locality Name
tls_k8s_head_info_L: 'BeiJing'

# 证书信息头, 组织 
# Organization Name 
tls_k8s_head_info_O: 'Kubernetes'

# 证书信息头, 组织单位 
# Organizational Units Name
tls_k8s_head_info_OU: 'Kubernetes'

# 证书信息头, 州或省 
# State or Province Name
tls_k8s_head_info_ST: 'BeiJing'

## Docker
## ********************************************************************************************************************************

# 使用 https://get.docker.com 方式安装, 并默认使用 Aliyun 镜像源, 可设为空.
docker_install_source: ""

# 镜像加速, 如果为空则不设置.
docker_registry_mirrors: '["https://registry.docker-cn.com"]'

# Docker 存储路径
docker_data_root: '/var/lib/docker'

# Docker Image 存储驱动 (此配置对 Centos 无效)
docker_storage_driver: "overlay2"

# 允许的不安全 Registry 地址
docker_insecure_registry: '[]'

# docker cgroup drive
docker_cgroup_drive: '{{ kubelet_cgroup_drive }}'

# docker login file size
docker_log_size: '1G'

# 是否配置 Daemon.js 
is_docker_daemon_config: true

## HaProxy
## ********************************************************************************************************************************

# HaProxy Version
# 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
# https://hub.docker.com/_/haproxy
haproxy_version: '2.0.8'

# 配置 stats 的 URI 地址
haproxy_stats_url: '/haproxy_stats'

# 监听 stats 的端口
haproxy_stats_port: 9090

# 访问 stats 时所需的账户/密码
haproxy_admin_username: 'crane'
haproxy_admin_password: 'crane'

# HaProxy Config Dir
haproxy_etc_dirs: '/etc/haproxy/'

## Configuration Directory
## ********************************************************************************************************************************

# Kubectl DirName
kubernetes_ctl_path: '/usr/local/bin/'

# Kubernetes PKI Path
kubernetes_pki_dirs: '{{ kubernetes_etc_dirs }}pki/'

# Etcd Config Path
kubernetes_etc_dirs: '/etc/kubernetes/'

# Kubernetes Manifests Path
kubernetes_manifests_dirs: '{{ kubernetes_etc_dirs }}manifests/'

# CNI Bin Path
kubernetes_cni_dirs: '/opt/cni/bin'

# Kubectl 工作目录
kubelet_work_dirs: '/var/lib/kubelet/'

# 前置临时目录
temporary_dirs: '/tmp/'

# Cgroup Drive (如果内核未达到 4.4.x 以上版本, 请改为 systemd, 否则低版本内核无法支持 cgroupfs 会造成集群无法启动)
kubelet_cgroup_drive: 'cgroupfs'

## Systemd Config
## ********************************************************************************************************************************

# Systemd 子配置文件目录
systemd_etc_dirs: '/etc/systemd/system/'

# Systemd 主配置文件目录
systemd_default_dirs: '/lib/systemd/system/'

## SSH
## ********************************************************************************************************************************

# 使用 Ansible 部署时连接实例的用户
ssh_connect_user: "{{ hostvars[inventory_hostname]['ansible_ssh_user'] }}"

# 使用 Ansible 部署时连接实例的 SSH 端口
ssh_connect_port: "{{ hostvars[inventory_hostname]['ansible_ssh_port'] }}"

# 使用 Ansible 部署时, 如需要节点之间进行协作传入的证书地址
target_ssh_private_key_file: "{{ temporary_dirs }}.general-id_rsa"

# 执行 SSH 或者 SCP 的公钥地址
ssh_public_key: "{{ target_ssh_private_key_file }}"

# 本地的公钥/私钥地址
source_ssh_public_key_file: "{{ hostvars[inventory_hostname]['ansible_ssh_public_key_file'] }}"
source_ssh_private_key_file: "{{ hostvars[inventory_hostname]['ansible_ssh_private_key_file'] }}"

## Etcd
## ********************************************************************************************************************************

# Etcd Verions
# https://github.com/etcd-io/etcd/releases
# 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
etcd_version: '3.3.15'

# Etcd 使用的 Client 协议, 默认 HTTPS, 不能修改
etcd_url_scheme: "https"

# Etcd 使用的 Cluster Peer 协议, 默认 HTTPS, 不能修改
etcd_peer_url_scheme: "https"

# Etcd Client TLS Auth
etcd_client_cert_auth: true

# Etcd Peer TLS Auth
etcd_peer_client_cert_auth: true

# Etcd Client Port
etcd_client_port: 2379

# Etcd Peer Port
etcd_peer_port: 2380

# Etcd Client TLS Auto
etcd_client_tls_auto: true

# Etcd Peer TLS Auto
etcd_peer_tls_auto: true

# Etcd Cluster Token
etcd_cluster_token: 'etcd-k8s-cluster'

# Etcd Cluster Type
etcd_cluster_type: 'new'

# 占位符
etcd_interface: ""

# Etcd Certs Path
etcd_ssl_dirs: '{{ kubernetes_pki_dirs }}etcd/'

# Etcd Data Path
etcd_data_dirs: '/var/lib/etcd/'


## Etcd TLS
## ********************************************************************************************************************************

# CFSSL 生成证书的加密方式
tls_etcd_encryption_algorithm: 'rsa'

# CFSSL 生成证书的通过加密算法生成的长度
tls_etcd_encryption_algorithm_size: 2048

# 证书有效期, 默认为 10 年, 因 CA 根证书默认为 5 年, 此值改大没意义
tls_etcd_validity_period: 5

# 证书信息头, 国家信息 
# Country Name
tls_etcd_head_info_C: 'CN'

# 证书信息头, 地区或城市 
# Locality Name
tls_etcd_head_info_L: 'BeiJing'

# 证书信息头, 组织 
# Organization Name 
tls_etcd_head_info_O: 'Etcd'

# 证书信息头, 组织单位 
# Organizational Units Name
tls_etcd_head_info_OU: 'Etcd'

# 证书信息头, 州或省 
# State or Province Name
tls_etcd_head_info_ST: 'BeiJing'

## Add Nodes
## ********************************************************************************************************************************

# Calico Pool CIDR
calico_ipv4_pool_cidr: '192.168.0.0/16'

# Calico Verion
# https://github.com/projectcalico/calico/releases
# 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
calico_version: 'v3.10.0'

# CNI Config Dir
cni_config_dir: '/etc/cni/net.d'

# 判定值, 勿动
is_add_master: "{{ inventory_hostname in groups['k8s-cluster-add-master'] }}"
is_add_node: "{{ inventory_hostname in groups['k8s-cluster-add-node'] }}"

## Kubernetes Add Ons
## ********************************************************************************************************************************

# DNS 服务所需的 Domain 后缀
dns_domain: 'cluster.local'

# DNS 服务的 ClusterIP 地址, 依赖集群 ClusterIP 网段
dns_cluster_ip: '10.96.0.10'

# DNS 集群 ClusterIP 网段
dns_cluster_range: "{{ k8s_cluster_ip_range }}"

# CoreDNS Version
# https://github.com/coredns/coredns/releases
# 如使用镜像方式部署, 不能修改 (如果可以使用 {{ k8s_cluster_component_registry }} 中的仓库地址获取镜像则可随意修改)
dns_version: '1.6.5'

## Helm
## ********************************************************************************************************************************

# 部署 Helm
is_deploy_helm: false

## Ingress Nginx
## ********************************************************************************************************************************

# 部署 Ingress Nginx
is_deploy_ingress_nginx: true

# Ingress Nginx Version
ingress_nginx_version: '0.26.1'

# 部署 Ingress Nginx Example
is_deploy_ingress_nginx_example: false

# Ingress Nginx Example Domain
# Ingres 示例使用的域名, 如果没有自定义域名, 可配置本机 Hosts
ingress_nginx_example: 'www.example.com'

## Prometheus Operator
## ********************************************************************************************************************************

# 部署 Prometheus Operator
is_deploy_prometheus_operator: false

# 部署 Prometheus Operator Ingress 所使用的 Ingress Domain
monitoring_ingress_prometheus_domain: 'prometheus.example.com'
monitoring_ingress_grafana_domain: 'grafana.example.com'
monitoring_ingress_alertmanager_domain: 'alertmanager.example.com'

# Prometheus Operator Grafana SMTP Configs
prometheus_operator_grafana_smtp_enable: true
prometheus_operator_grafana_smtp_password: ''
prometheus_operator_grafana_smtp_server: 'smtp.126.com:465'
prometheus_operator_grafana_smtp_user: 'shileizcc@126.com'
prometheus_operator_grafana_smtp_from_address: 'shileizcc@126.com'

## DNS Example
## ********************************************************************************************************************************

# 部署 DNS Example Tools
# 用来测试集群内是否 DNS 可用的 Tools Pods
is_deploy_busybox_example: false

## Istio
## ********************************************************************************************************************************

# 部署 Istio
# 注意 部署 Istio 不建议与 Prometheus Operator 一同部署, 可能会引发服务之间的冲突问题, 如需一同部署请自行解决依赖
is_deploy_istio: false

# Istio Version
# https://github.com/istio/istio/releases
istio_version: '1.3.3'

# 部署 Istio 所使用的 Ingress Domain
istio_ingress_prometheus_domain: 'prometheus.example.com'
istio_ingress_grafana_domain: 'grafana.example.com'
istio_ingress_tracing_domain: 'tracing.example.com'
istio_ingress_kiali_domain: 'kiali.example.com'

# istio kiali user/pass base64 coding, default admin
istio_kiali_username: 'YWRtaW4='
istio_kiali_password: 'YWRtaW4='

# 部署 upload service
is_deploy_upload_service: false

upload_service_ingress_domain: 'upload.example.com'

## Harbor
## ********************************************************************************************************************************

# Harbor Deploy enable
is_deploy_harbor: false

# Harbor Deploy Namespace
harbor_namespace: 'harbor'

# Harbor Admin Password
harbor_admin_password: 'Harbor12345'

# Harbor PostGreSQL Password
harbor_pg_admin_password: 'changeit'
harbor_pg_clair_password: 'changeit'

# Harbor Core Secure Key
harbor_core_secure_key: 'not-a-secure-key' 
harbor_core_secret: '90USoEBlROrSey6F'

# Harbor Registry Secure
harbor_registry_secure_key: 'iCELcbcIHHG4RSua'
harbor_registry_redis_password: ''

# Harbor JobService Secure
harbor_jobservice_secure_key: 'L1Jp8tCQngTlftfO'

# Harbor chartmuseum Secure
harbor_chartmuseum_redis_password: ''

# Harbor Domain
harbor_ingress_default_domain: 'harbor.example.com'
harbor_ingress_notary_domain: 'notary.example.com'

# CFSSL 生成证书的加密方式
tls_harbor_server_encryption_algorithm: 'rsa'
tls_harbor_client_encryption_algorithm: 'rsa'

# CFSSL 生成证书的通过加密算法生成的长度
tls_harbor_server_encryption_algorithm_size: 2048
tls_harbor_client_encryption_algorithm_size: 2048

# 证书有效期, 默认为 5 年, 因 CA 根证书默认为 5 年, 此值改大没意义
tls_harbor_server_validity_period: 5
tls_harbor_client_validity_period: 5

# 证书信息头, 国家信息 
# Country Name
tls_harbor_server_head_info_C: 'CN'
tls_harbor_client_head_info_C: 'CN'

# 证书信息头, 地区或城市 
# Locality Name
tls_harbor_server_head_info_L: 'BeiJing'
tls_harbor_client_head_info_L: 'BeiJing'

# 证书信息头, 组织 
# Organization Name 
tls_harbor_server_head_info_O: 'Harbor'
tls_harbor_client_head_info_O: 'Harbor'

# 证书信息头, 组织单位 
# Organizational Units Name
tls_harbor_server_head_info_OU: 'Harbor'
tls_harbor_client_head_info_OU: 'Harbor'

# 证书信息头, 州或省 
# State or Province Name
tls_harbor_server_head_info_ST: 'BeiJing'
tls_harbor_client_head_info_ST: 'BeiJing'

# Docs https://wiki.shileizcc.com/confluence/display/KUB/Kubernetes+Harbor

## Clean Kubernetes Cluster
## ********************************************************************************************************************************
# 初始化时, 是否进行 Clean, 如果是全新的环境可以不开启, 如果之前部署过或者使用 kubeadm 进行部署则需要开启此配置,
# 应避免部署时影响效率
is_initialize_clean: false

# 清除集群时是否删除 Docker
is_remove_docker_ce: false

# 清除 Docker CE 时清除数据目录
is_remove_docker_dir: false

# 清除集群时是否删除 CFSSL 可执行文件
is_remove_cfssl: true

# 清除集群时是否删除 CNI 插件
is_remove_cni: true

# 是否清楚 Kubelet Kubectl 可执行文件
is_remove_k8s_binary: true